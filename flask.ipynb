{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " * Serving Flask app \"__main__\" (lazy loading)\n",
      " * Environment: production\n",
      "   WARNING: This is a development server. Do not use it in a production deployment.\n",
      "   Use a production WSGI server instead.\n",
      " * Debug mode: off\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " * Running on http://127.0.0.1:5000/ (Press CTRL+C to quit)\n",
      "127.0.0.1 - - [14/Mar/2021 21:16:28] \"\u001b[37mGET / HTTP/1.1\u001b[0m\" 200 -\n",
      "127.0.0.1 - - [14/Mar/2021 21:16:28] \"\u001b[36mGET /static/css/style.css HTTP/1.1\u001b[0m\" 304 -\n",
      "127.0.0.1 - - [14/Mar/2021 21:16:28] \"\u001b[33mGET /favicon.ico HTTP/1.1\u001b[0m\" 404 -\n",
      "127.0.0.1 - - [14/Mar/2021 21:16:30] \"\u001b[37mPOST /login HTTP/1.1\u001b[0m\" 200 -\n",
      "127.0.0.1 - - [14/Mar/2021 21:16:49] \"\u001b[37mPOST /uploader HTTP/1.1\u001b[0m\" 200 -\n",
      "127.0.0.1 - - [14/Mar/2021 21:16:49] \"\u001b[37mGET /static/js/RGraph.common.tooltips.js HTTP/1.1\u001b[0m\" 200 -\n",
      "127.0.0.1 - - [14/Mar/2021 21:16:49] \"\u001b[37mGET /static/js/RGraph.common.key.js HTTP/1.1\u001b[0m\" 200 -\n",
      "127.0.0.1 - - [14/Mar/2021 21:16:49] \"\u001b[37mGET /static/js/RGraph.common.dynamic.js HTTP/1.1\u001b[0m\" 200 -\n",
      "127.0.0.1 - - [14/Mar/2021 21:16:50] \"\u001b[37mGET /static/js/RGraph.common.core.js HTTP/1.1\u001b[0m\" 200 -\n",
      "127.0.0.1 - - [14/Mar/2021 21:16:50] \"\u001b[37mGET /static/js/RGraph.hbar.js HTTP/1.1\u001b[0m\" 200 -\n",
      "127.0.0.1 - - [14/Mar/2021 21:16:55] \"\u001b[37mGET /uploader/data/4 HTTP/1.1\u001b[0m\" 200 -\n",
      "127.0.0.1 - - [14/Mar/2021 21:21:47] \"\u001b[37mPOST /input_percent HTTP/1.1\u001b[0m\" 200 -\n"
     ]
    }
   ],
   "source": [
    "from flask import Flask, flash , redirect, render_template , request, session, abort , Markup\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import keras\n",
    "from keras.models import load_model\n",
    "from keras import backend as K\n",
    "from werkzeug.utils import secure_filename\n",
    "import json\n",
    "import csv\n",
    "\n",
    "app = Flask(__name__)\n",
    "app.secret_key = os.urandom(12)\n",
    "\n",
    "dropdown_list = []\n",
    "dropdown_list_2 = []\n",
    "\n",
    "#saving filename of upload file\n",
    "def sav_name(n):\n",
    "    with open(\"filename.txt\", \"w\") as ff:\n",
    "        ff.write(n)\n",
    "#preprocessing data of uploaded file        \n",
    "def preprocess_data():\n",
    "    dataset = pd.read_csv('Churn_Modelling.csv')\n",
    "    ffr = open(\"filename.txt\", \"r\")\n",
    "    upl_file = ffr.read()\n",
    "    upl_file = str(upl_file)\n",
    "    test = pd.read_csv(upl_file)\n",
    "\n",
    "    \n",
    "    X_test = test.iloc[:, 3:13].values\n",
    "    X = dataset.iloc[:, 3:13].values\n",
    "    y= dataset.iloc[:, 13].values\n",
    "    y_test= test.iloc[:, 13].values\n",
    "\n",
    "    from sklearn.preprocessing import LabelEncoder, OneHotEncoder\n",
    "    from sklearn.compose import ColumnTransformer\n",
    "    labelencoder_X_1 = LabelEncoder()\n",
    "    X[:, 1] = labelencoder_X_1.fit_transform(X[:, 1])\n",
    "    labelencoder_X_2 = LabelEncoder()\n",
    "    X[:, 2] = labelencoder_X_2.fit_transform(X[:, 2])\n",
    "\n",
    "    transformer = ColumnTransformer([('one_hot_encoder', OneHotEncoder(), [1])],remainder='passthrough')\n",
    "    X = np.array(transformer.fit_transform(X), dtype=np.float)\n",
    "    X=X[:,1:]\n",
    "    #onehotencoder = OneHotEncoder(categorical_features = [1])\n",
    "    #X = onehotencoder.fit_transform(X).toarray()\n",
    "    labelencoder_X_3 = LabelEncoder()#creating label encoder object no. 1 to encode region name(index 1 in features)\n",
    "    X_test[:, 1] = labelencoder_X_3.fit_transform(X_test[:, 1])#encoding region from string to just 3 no.s 0,1,2 respectively\n",
    "    labelencoder_X_4 = LabelEncoder()\n",
    "    X_test[:, 2] = labelencoder_X_4.fit_transform(X_test[:, 2])#encoding Gender from string to just 2 no.s 0,1(male,female) respectively\n",
    "\n",
    "    transformer = ColumnTransformer([('one_hot_encoder', OneHotEncoder(), [1])],remainder='passthrough')\n",
    "    X_test = np.array(transformer.fit_transform(X_test), dtype=np.float)\n",
    "    #onehotencoder2 = OneHotEncoder(categorical_features = [1])\n",
    "    #X_test= onehotencoder2.fit_transform(X_test).toarray()\n",
    "    X_test = X_test[:, 1:]\n",
    "\n",
    "\n",
    "    from sklearn.model_selection import train_test_split\n",
    "    X_train=X\n",
    "    y_train=y\n",
    "\n",
    "\n",
    "    from sklearn.preprocessing import StandardScaler\n",
    "    sc = StandardScaler()\n",
    "    X_train = sc.fit_transform(X_train)\n",
    "    X_test = sc.transform(X_test)\n",
    "\n",
    "    return X_test\n",
    "#preprocessing data of default file\n",
    "def preprocess_data_default():\n",
    "    dataset = pd.read_csv('Churn_Modelling.csv')\n",
    "    fpath = os.path.join(\"default\", \"testtestdefault1.csv\")\n",
    "    test = pd.read_csv(fpath)\n",
    "    X_test = test.iloc[:, 3:13].values\n",
    "    X = dataset.iloc[:, 3:13].values\n",
    "    y= dataset.iloc[:, 13].values\n",
    "    y_test= test.iloc[:, 13].values\n",
    "\n",
    "    from sklearn.preprocessing import LabelEncoder, OneHotEncoder\n",
    "    from sklearn.compose import ColumnTransformer\n",
    "    labelencoder_X_1 = LabelEncoder()\n",
    "    X[:, 1] = labelencoder_X_1.fit_transform(X[:, 1])\n",
    "    labelencoder_X_2 = LabelEncoder()\n",
    "    X[:, 2] = labelencoder_X_2.fit_transform(X[:, 2])\n",
    "    \n",
    "    transformer = ColumnTransformer([('one_hot_encoder', OneHotEncoder(), [1])],remainder='passthrough')\n",
    "    X = np.array(transformer.fit_transform(X), dtype=np.float)\n",
    "    #onehotencoder = OneHotEncoder(categorical_features = [1])\n",
    "    #X = onehotencoder.fit_transform(X).toarray()\n",
    "    X = X[:, 1:]\n",
    "\n",
    "    labelencoder_X_3 = LabelEncoder()#creating label encoder object no. 1 to encode region name(index 1 in features)\n",
    "    X_test[:, 1] = labelencoder_X_3.fit_transform(X_test[:, 1])#encoding region from string to just 3 no.s 0,1,2 respectively\n",
    "    labelencoder_X_4 = LabelEncoder()\n",
    "    X_test[:, 2] = labelencoder_X_4.fit_transform(X_test[:, 2])#encoding Gender from string to just 2 no.s 0,1(male,female) respectively\n",
    "\n",
    "    #onehotencoder2 = OneHotEncoder(categorical_features = [1])\n",
    "    #X_test= onehotencoder2.fit_transform(X_test).toarray()\n",
    "    transformer = ColumnTransformer([('one_hot_encoder', OneHotEncoder(), [1])],remainder='passthrough')\n",
    "    X_test = np.array(transformer.fit_transform(X_test), dtype=np.float)\n",
    "    X_test = X_test[:, 1:]\n",
    "\n",
    "\n",
    "    from sklearn.model_selection import train_test_split\n",
    "    X_train=X\n",
    "    y_train=y\n",
    "\n",
    "\n",
    "    from sklearn.preprocessing import StandardScaler\n",
    "    sc = StandardScaler()\n",
    "    X_train = sc.fit_transform(X_train)\n",
    "    X_test = sc.transform(X_test)\n",
    "\n",
    "    return X_test\n",
    "# predicting reason for leaving percentage of specific member of uploaded file   \n",
    "def model_2(cid1):\n",
    "    dataset = pd.read_csv('Churn_Modelling.csv')\n",
    "    data_re=dataset[dataset['Exited']==1]\n",
    "    data_re.set_index('RowNumber',inplace=True)\n",
    "    data_re.to_csv('data_re.csv')\n",
    "    X = dataset.iloc[:, 3:14].values\n",
    "    test=pd.read_csv('testtest1.csv')\n",
    "    cid1 = int(cid1)\n",
    "\n",
    "    from sklearn.preprocessing import LabelEncoder, OneHotEncoder\n",
    "    from sklearn.compose import ColumnTransformer\n",
    "    labelencoder_X_1 = LabelEncoder()\n",
    "    X[:, 1] = labelencoder_X_1.fit_transform(X[:, 1])\n",
    "    labelencoder_X_2 = LabelEncoder()\n",
    "    X[:, 2] = labelencoder_X_2.fit_transform(X[:, 2])\n",
    "\n",
    "    X_train=X\n",
    "\n",
    "    X_test=test.loc[test['CustomerId']==cid1].values.copy()\n",
    "    X_test=X_test[:, 3:14]\n",
    "    from sklearn.preprocessing import LabelEncoder, OneHotEncoder\n",
    "    from sklearn.compose import ColumnTransformer\n",
    "    labelencoder_X_3 = LabelEncoder()#creating label encoder object no. 1 to encode region name(index 1 in features)\n",
    "    X_test[:,1] = labelencoder_X_3.fit_transform(X_test[:, 1])#encoding region from string to just 3 no.s 0,1,2 respectively\n",
    "    labelencoder_X_4 = LabelEncoder()\n",
    "    X_test[:,2] = labelencoder_X_4.fit_transform(X_test[:, 2])      \n",
    "    from sklearn.preprocessing import StandardScaler\n",
    "    sc = StandardScaler()\n",
    "    X_train = sc.fit_transform(X_train)\n",
    "    X_test = sc.transform(X_test)\n",
    "\n",
    "    return X_test\n",
    "# predicting reason for leaving percentage of specific member of default file   \n",
    "def model_default_2(cid1):\n",
    "    dataset = pd.read_csv('Churn_Modelling.csv')\n",
    "    data_re=dataset[dataset['Exited']==1]\n",
    "    data_re.set_index('RowNumber',inplace=True)\n",
    "    data_re.to_csv('data_re.csv')\n",
    "    X = dataset.iloc[:, 3:14].values\n",
    "    fpathr = os.path.join(\"default\", \"testtestreason1.csv\")\n",
    "    test = pd.read_csv(fpathr)\n",
    "    cid1 = int(cid1)\n",
    "\n",
    "    from sklearn.preprocessing import LabelEncoder, OneHotEncoder\n",
    "    labelencoder_X_1 = LabelEncoder()\n",
    "    X[:, 1] = labelencoder_X_1.fit_transform(X[:, 1])\n",
    "    labelencoder_X_2 = LabelEncoder()\n",
    "    X[:, 2] = labelencoder_X_2.fit_transform(X[:, 2])\n",
    "\n",
    "    X_train=X\n",
    "\n",
    "    X_test=test.loc[test['CustomerId']==cid1].values.copy()\n",
    "    X_test=X_test[:, 3:14]\n",
    "    from sklearn.preprocessing import LabelEncoder, OneHotEncoder\n",
    "    labelencoder_X_3 = LabelEncoder()#creating label encoder object no. 1 to encode region name(index 1 in features)\n",
    "    X_test[:,1] = labelencoder_X_3.fit_transform(X_test[:, 1])#encoding region from string to just 3 no.s 0,1,2 respectively\n",
    "    labelencoder_X_4 = LabelEncoder()\n",
    "    X_test[:,2] = labelencoder_X_4.fit_transform(X_test[:, 2])      \n",
    "    from sklearn.preprocessing import StandardScaler\n",
    "    sc = StandardScaler()\n",
    "    X_train = sc.fit_transform(X_train)\n",
    "    X_test = sc.transform(X_test)\n",
    "\n",
    "    return X_test\n",
    "#search for specific id from uploaded file\n",
    "def search(cid):\n",
    "    with open('testtest1.csv') as file:\n",
    "        allRead = csv.reader(file, delimiter=',')\n",
    "        for row in allRead:\n",
    "            if row[1]==cid:\n",
    "                return row\n",
    "#search for specific id from default file\n",
    "def search_default(cid):\n",
    "    fpathr = os.path.join(\"default\", \"testtestreason1.csv\")\n",
    "    with open(fpathr) as file:\n",
    "        allRead = csv.reader(file, delimiter=',')\n",
    "        for row in allRead:\n",
    "            if row[1]==cid:\n",
    "                return row\n",
    "\n",
    "#login check page\n",
    "@app.route('/')\n",
    "def home():\n",
    "    if not session.get('logged_in'):\n",
    "        return render_template('login.html')\n",
    "    else:\n",
    "        return render_template('upload.html')\n",
    "\n",
    "#uploading page\n",
    "@app.route('/upload')\n",
    "def upload_file():\n",
    "   dropdown_list.clear()\n",
    "   dropdown_list_2.clear()\n",
    "   return render_template('upload.html')\n",
    "\n",
    "#getting predicted data in dropdown list of uploaded file \n",
    "@app.route('/uploader', methods = ['GET', 'POST'])\n",
    "def uploader_file():\n",
    "   if request.method == 'POST':\n",
    "      K.clear_session()\n",
    "      dropdown_list.clear()\n",
    "      f = request.files['file']\n",
    "      f.save(secure_filename(f.filename))\n",
    "      sav_name(f.filename)\n",
    "      ffr = open(\"filename.txt\", \"r\")\n",
    "      upl_file = ffr.read()\n",
    "      upl_file = str(upl_file)\n",
    "      test = preprocess_data()\n",
    "      model = load_model('my_model.h5')\n",
    "      #model._make_predict_function()\n",
    "      y_pred = model.predict(test)\n",
    "      dff = pd.read_csv(upl_file)\n",
    "      dff['Exited'] = y_pred\n",
    "      dff.set_index('RowNumber', inplace=True)\n",
    "      dff.sort_values('Exited', ascending=False, inplace=True)\n",
    "      dff.to_csv('testtest1.csv')  # output file\n",
    "      with open(upl_file) as file:\n",
    "            allRead = csv.reader(file, delimiter=',')\n",
    "            lineCount = 0\n",
    "            for row in allRead:\n",
    "                if lineCount==0:\n",
    "                    lineCount=lineCount+1\n",
    "                else:\n",
    "                    lineCount=lineCount+1\n",
    "                    dropdown_list.append((row[1]))\n",
    "              \n",
    "      return render_template('mytemplate3.html',  dropdown_list=dropdown_list)\n",
    "\n",
    "\n",
    " #getting only top % inserted from uploaded file \n",
    "@app.route('/input_percent' , methods = ['GET','POST'])\n",
    "def input_num():\n",
    "    x = request.form[\"in\"]\n",
    "    line = pd.read_csv(\"testtest1.csv\").shape[0]\n",
    "    y = round((float(x)*line)/100)\n",
    "    ls = []\n",
    "    lschurn=[]\n",
    "    with open(\"testtest1.csv\") as file:\n",
    "        allRead = csv.reader(file, delimiter=',')\n",
    "        lineCount = 0\n",
    "        for row in allRead:\n",
    "            if lineCount == 0:\n",
    "                lineCount += 1\n",
    "            elif lineCount <= y and lineCount != 0:\n",
    "                ls.append(row[1])\n",
    "                lschurn.append(row[13])\n",
    "                lineCount += 1\n",
    "    lss=list(map(lambda x: float(x*100),list(pd.read_csv(\"testtest1.csv\")['Exited'][:y].copy())))  \n",
    "    return render_template('mytemplate3_percent.html', outList = ls, value_list=lschurn,values_res=lss )\n",
    "\n",
    "\n",
    " #getting only top % inserted from default file\n",
    "@app.route('/input_percent_default' , methods = ['GET','POST'])\n",
    "def input_num_default():\n",
    "    x = request.form[\"in\"]\n",
    "    fpathr = os.path.join(\"default\", \"testtestreason1.csv\")\n",
    "    line = pd.read_csv(fpathr).shape[0]\n",
    "    y = round((float(x)*line)/100)\n",
    "    ls = []\n",
    "    lschurn=[]\n",
    "    with open(fpathr) as file:\n",
    "        allRead = csv.reader(file, delimiter=',')\n",
    "        lineCount = 0\n",
    "        for row in allRead:\n",
    "            if lineCount == 0:\n",
    "                lineCount += 1\n",
    "            elif lineCount <= y and lineCount != 0:\n",
    "                ls.append(row[1])\n",
    "                lschurn.append(row[13])\n",
    "                lineCount += 1\n",
    "    lss=list(map(lambda x: float(x*100),list(pd.read_csv(fpathr)['Exited'][:y].copy())))              \n",
    "    return render_template('mytemplate4_percent.html', outList = ls , value_list=lschurn , values_res=lss)\n",
    "\n",
    " #getting only top 2 id from uploaded file\n",
    "@app.route('/uploader/data/2', methods=['GET', 'POST'])\n",
    "def check_number():\n",
    "    x = 2\n",
    "    ls = []\n",
    "    lschurn=[]\n",
    "\n",
    "    with open(\"testtest1.csv\") as file:\n",
    "        allRead = csv.reader(file, delimiter=',')\n",
    "        lineCount = 0\n",
    "        for row in allRead:\n",
    "            if lineCount == 0:\n",
    "                lineCount += 1\n",
    "            elif lineCount <= x and lineCount != 0:\n",
    "                ls.append(row[1])\n",
    "                lschurn.append(row[13])\n",
    "                lineCount += 1\n",
    "    lss=list(map(lambda x: float(x*100),list(pd.read_csv(\"testtest1.csv\")['Exited'][:2].copy())))            \n",
    "    return render_template('mytemplate3_percent.html', outList = ls, value_list=lschurn , values_res=lss)\n",
    "\n",
    "\n",
    " #getting only top 4 id from uploaded file\n",
    "@app.route('/uploader/data/4', methods=['GET', 'POST'])\n",
    "def check_number2():\n",
    "    x = 4\n",
    "    ls = []\n",
    "    lschurn=[]\n",
    "\n",
    "    with open(\"testtest1.csv\") as file:\n",
    "        allRead = csv.reader(file, delimiter=',')\n",
    "        lineCount = 0\n",
    "        for row in allRead:\n",
    "            if lineCount==0:\n",
    "                lineCount+=1\n",
    "            elif lineCount <= x and lineCount != 0:\n",
    "                ls.append(row[1])\n",
    "                lschurn.append(row[13])\n",
    "                lineCount += 1\n",
    "\n",
    "    lss=list(map(lambda x: float(x*100),list(pd.read_csv(\"testtest1.csv\")['Exited'][:4].copy()))) \n",
    "    return render_template('mytemplate3_percent.html', outList = ls, value_list=lschurn , values_res=lss)\n",
    "\n",
    " #getting predicted data in dropdown list of default file \n",
    "@app.route('/defaultfile', methods = ['GET', 'POST'])\n",
    "def uploader_default_file():\n",
    "      K.clear_session()\n",
    "      dropdown_list_2.clear()\n",
    "      test = preprocess_data_default()\n",
    "      model = load_model('my_model.h5')\n",
    "      #model._make_predict_function()\n",
    "      y_pred = model.predict(test)\n",
    "      fpath = os.path.join(\"default\", \"testtestdefault1.csv\")\n",
    "      dff = pd.read_csv(fpath)\n",
    "      dff['Exited'] = y_pred\n",
    "      dff.set_index('RowNumber', inplace=True)\n",
    "      dff.sort_values('Exited', ascending=False, inplace=True)\n",
    "      fpathr = os.path.join(\"default\", \"testtestreason1.csv\")\n",
    "      dff.to_csv(fpathr)  # output file\n",
    "      with open(fpath) as file:\n",
    "            allRead = csv.reader(file, delimiter=',')\n",
    "            lineCount = 0\n",
    "            for row in allRead:\n",
    "                if lineCount==0:\n",
    "                    lineCount=lineCount+1\n",
    "                else:\n",
    "                    lineCount=lineCount+1\n",
    "                    dropdown_list_2.append((row[1]))\n",
    "                \n",
    "      return render_template('mytemplate4.html',  dropdown_list_2=dropdown_list_2)\n",
    "\n",
    "\n",
    " #getting only top 2 id from default file\n",
    "@app.route('/uploader/data_default/2', methods=['GET', 'POST'])\n",
    "def check_number_default():\n",
    "    x = 2\n",
    "    ls = []\n",
    "    lschurn=[]\n",
    "    fpathr = os.path.join(\"default\", \"testtestreason1.csv\")\n",
    "    with open(fpathr) as file:\n",
    "        allRead = csv.reader(file, delimiter=',')\n",
    "        lineCount = 0\n",
    "        for row in allRead:\n",
    "            if lineCount == 0:\n",
    "                lineCount += 1\n",
    "            elif lineCount <= x and lineCount != 0:\n",
    "                ls.append(row[1])\n",
    "                lschurn.append(row[13])\n",
    "                lineCount += 1\n",
    "    lss=list(map(lambda x: float(x*100),list(pd.read_csv(fpathr)['Exited'][:2].copy())))               \n",
    "\n",
    "    return render_template('mytemplate4_percent.html', outList = ls, value_list=lschurn , values_res=lss)\n",
    "\n",
    "\n",
    " #getting only top 4 id from default file\n",
    "@app.route('/uploader/data_default/4', methods=['GET', 'POST'])\n",
    "def check_number_default2():\n",
    "    x = 4\n",
    "    ls = []\n",
    "    lschurn=[]\n",
    "    fpathr = os.path.join(\"default\", \"testtestreason1.csv\")\n",
    "    with open(fpathr) as file:\n",
    "        allRead = csv.reader(file, delimiter=',')\n",
    "        lineCount = 0\n",
    "        for row in allRead:\n",
    "            if lineCount==0:\n",
    "                lineCount+=1\n",
    "            elif lineCount <= x and lineCount != 0:\n",
    "                ls.append(row[1])\n",
    "                lschurn.append(row[13])\n",
    "                lineCount += 1\n",
    "    lss=list(map(lambda x: float(x*100),list(pd.read_csv(fpathr)['Exited'][:4].copy())))              \n",
    "    return render_template('mytemplate4_percent.html', outList = ls, value_list=lschurn , values_res=lss)\n",
    "\n",
    "#displaying final full data predicted of selected customer from uploaded file\n",
    "@app.route('/check/<string:dropdown>',methods=['POST','GET'])\n",
    "def specific(dropdown):\n",
    "    x = dropdown\n",
    "    yy,yo = predict(x)\n",
    "    x = search(x)\n",
    "    rownum  = x[0]\n",
    "    ccid = x[1]\n",
    "    surname = x[2]\n",
    "    creditscore  = x[3]\n",
    "    geo = x[4]\n",
    "    gender  = x[5]\n",
    "    age  = x[6]\n",
    "    tenure = x[7]\n",
    "    balance  = x[8]\n",
    "    numpro = x[9]\n",
    "    hascard = x[10]\n",
    "    activemem = x[11]\n",
    "    salary = x[12]    \n",
    "    x = x[13]\n",
    "    pred= float(x)*100\n",
    "    labels = [\"probability\",\"\"]\n",
    "    values = [pred]\n",
    "    labels_res = [\"Excess Documents Required\",\"High Service Charges/Rate of Interest\",\"Inexperienced Staff / Bad customer service\",\"Long Response Times\"]\n",
    "    values_res = [float(i)*100 for i in yo[0]]\n",
    "    x = float(x)*100\n",
    "    x = round(x,2)\n",
    "    values_res[0] = round(values_res[0],2)\n",
    "    values_res[1] = round(values_res[1],2)\n",
    "    values_res[2] = round(values_res[2],2)\n",
    "    values_res[3] = round(values_res[3],2)\n",
    "    colors = [ \"#F7464A\", \"#46BFBD\", \"#FDB45C\",  \"#ABCDEF\"]\n",
    "    return render_template('chart_meter.html', set=zip(values_res, labels_res, colors),firstname=x, rownum=rownum, ccid=ccid, surname=surname, creditscore=creditscore, geo=geo, gender=gender, age=age, tenure=tenure, balance=balance, numpro=numpro, hascard = hascard, activemem = activemem, salary = salary, secondname = values_res[0] , secondname1 = values_res[1] , secondname2 = values_res[2] , secondname3 = values_res[3] ,labels_res=labels_res,values_res=values_res, values=values, labels=labels)\n",
    "\n",
    "#displaying final full data predicted of selected customer from default file\n",
    "@app.route('/check_default/<string:dropdown_2>',methods=['POST','GET'])\n",
    "def specific_default(dropdown_2):\n",
    "    x = dropdown_2\n",
    "    yy,yo = predict_default(x)\n",
    "    x = search_default(x)\n",
    "    rownum  = x[0]\n",
    "    ccid = x[1]\n",
    "    surname = x[2]\n",
    "    creditscore  = x[3]\n",
    "    geo = x[4]\n",
    "    gender  = x[5]\n",
    "    age  = x[6]\n",
    "    tenure = x[7]\n",
    "    balance  = x[8]\n",
    "    numpro = x[9]\n",
    "    hascard = x[10]\n",
    "    activemem = x[11]\n",
    "    salary = x[12]\n",
    "    x = x[13]\n",
    "    pred= float(x)*100\n",
    "    labels = [\"probability\",\"\"]\n",
    "    values = [pred]\n",
    "    labels_res = [\"Excess Documents Required\",\"High Service Charges/Rate of Interest\",\"Inexperienced Staff / Bad customer service\",\"Long Response Times\"]\n",
    "    values_res = [float(i)*100 for i in yo[0]]\n",
    "    x = float(x)*100\n",
    "    x = round(x,2)\n",
    "    values_res[0] = round(values_res[0],2)\n",
    "    values_res[1] = round(values_res[1],2)\n",
    "    values_res[2] = round(values_res[2],2)\n",
    "    values_res[3] = round(values_res[3],2)\n",
    "    colors = [ \"#F7464A\", \"#46BFBD\", \"#FDB45C\" , \"#ABCDEF\"]\n",
    "    return render_template('chart_meter.html', set=zip(values_res, labels_res, colors),firstname=x, rownum=rownum, ccid=ccid, surname=surname, creditscore=creditscore, geo=geo, gender=gender, age=age, tenure=tenure, balance=balance, numpro=numpro, hascard = hascard, activemem = activemem, salary = salary, secondname = values_res[0] , secondname1 = values_res[1] , secondname2 = values_res[2] , secondname3 = values_res[3] ,labels_res=labels_res,values_res=values_res, values=values, labels=labels)\n",
    "\n",
    "#login page\n",
    "@app.route('/login', methods=['GET', 'POST'])\n",
    "def do_admin_login():\n",
    "    error = None\n",
    "    if request.form['username'] != 'dhfl' or request.form['password'] != 'dhfl':\n",
    "        error = 'Invalid username or password. Please try again!'\n",
    "    else:\n",
    "        flash('You were successfully logged in')\n",
    "        session['logged_in'] = True\n",
    "        return home()\n",
    "\n",
    "    return render_template('login.html', error=error)\n",
    "\n",
    "#logout page\n",
    "@app.route(\"/logout\")\n",
    "def logout():\n",
    "    session['logged_in'] = False\n",
    "    session.clear()\n",
    "    ffr = open(\"filename.txt\", \"r\")\n",
    "    upl_file = ffr.read()\n",
    "    upl_file = str(upl_file)\n",
    "    if os.path.exists(upl_file):\n",
    "        os.remove(upl_file)\n",
    "\n",
    "    if os.path.exists('testtest1.csv'):\n",
    "        os.remove('testtest1.csv')\n",
    "    return home()\n",
    "\n",
    "#return to uploading page\n",
    "@app.route(\"/backtofile\")\n",
    "def backtofile():\n",
    "    session['logged_in'] = True\n",
    "    ffr = open(\"filename.txt\", \"r\")\n",
    "    upl_file = ffr.read()\n",
    "    upl_file = str(upl_file)\n",
    "    if os.path.exists(upl_file):\n",
    "        os.remove(upl_file)\n",
    "\n",
    "    if os.path.exists('testtest1.csv'):\n",
    "        os.remove('testtest1.csv')\n",
    "    return home()\n",
    "\n",
    "#predicting churn risk % for uploaded file\n",
    "@app.route(\"/predict\", methods=[\"GET\",\"POST\"])\n",
    "def predict(z):\n",
    "     K.clear_session()\n",
    "     test = preprocess_data()\n",
    "     model = load_model('my_model.h5')\n",
    "     #model._make_predict_function()\n",
    "     y_pred = model.predict(test)\n",
    "     ffr = open(\"filename.txt\", \"r\")\n",
    "     upl_file = ffr.read()\n",
    "     upl_file = str(upl_file)\n",
    "     dff = pd.read_csv(upl_file)\n",
    "     dff['Exited'] = y_pred\n",
    "     dff.set_index('RowNumber', inplace=True)\n",
    "     dff.sort_values('Exited', ascending=False, inplace=True)\n",
    "     dff.to_csv('testtest1.csv')  # output file\n",
    "     cid1 = z \n",
    "     test3 = model_2(cid1)\n",
    "     model2 = load_model('my_model2.h5')\n",
    "     #model2._make_predict_function()\n",
    "     y_pred2 = model2.predict(test3)\n",
    "     y_pred = y_pred.tolist()\n",
    "     resons=[\"Excess Documents Required\",\"High Service Charges/Rate of Interest\",\"Inexperienced Staff / Bad customer service\",\"Long Response Times\"]\n",
    "     dic=dict()\n",
    "     diff=list()\n",
    "     for j in range(len(y_pred2)):\n",
    "        dic.clear()\n",
    "        for (label, p) in zip(resons, y_pred2[j]):\n",
    "            dic[label]= p*100\n",
    "        diff.append(dic.copy())\n",
    "     j = json.dumps(diff)\n",
    "     K.clear_session()\n",
    "     \n",
    "     return j,y_pred2\n",
    "\n",
    "\n",
    "#predicting churn risk % for default file\n",
    "@app.route(\"/predict_default\", methods=[\"GET\",\"POST\"])\n",
    "def predict_default(z):\n",
    "     K.clear_session()\n",
    "     test = preprocess_data_default()\n",
    "     model = load_model('my_model.h5')\n",
    "     #model._make_predict_function()\n",
    "     y_pred = model.predict(test)\n",
    "     fpath = os.path.join(\"default\", \"testtestdefault1.csv\")\n",
    "     dff = pd.read_csv(fpath)\n",
    "     dff['Exited'] = y_pred\n",
    "     dff.set_index('RowNumber', inplace=True)\n",
    "     dff.sort_values('Exited', ascending=False, inplace=True)\n",
    "     fpathr = os.path.join(\"default\", \"testtestreason1.csv\")\n",
    "     dff.to_csv(fpathr)  # output file\n",
    "     cid1 = z \n",
    "     test3 = model_default_2(cid1)\n",
    "     model2 = load_model('my_model2.h5')\n",
    "     #model2._make_predict_function()\n",
    "     y_pred2 = model2.predict(test3)\n",
    "     y_pred = y_pred.tolist()\n",
    "     resons=[\"Excess Documents Required\",\"High Service Charges/Rate of Interest\",\"Inexperienced Staff / Bad customer service\",\"Long Response Times\"]\n",
    "     dic=dict()\n",
    "     diff=list()\n",
    "     for j in range(len(y_pred2)):\n",
    "        dic.clear()\n",
    "        for (label, p) in zip(resons, y_pred2[j]):\n",
    "            dic[label]= p*100\n",
    "        diff.append(dic.copy())\n",
    "     j = json.dumps(diff)\n",
    "     K.clear_session()\n",
    "     \n",
    "     return j,y_pred2\n",
    "\n",
    "    \n",
    "if __name__ == \"__main__\":\n",
    "    app.run()\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
